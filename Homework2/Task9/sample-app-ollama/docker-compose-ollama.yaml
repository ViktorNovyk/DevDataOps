services:
  ollama:
    image: ollama/ollama:0.12.3
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    healthcheck:
      test: [ "CMD-SHELL", "ollama list || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    volumes:
      - ollama:/root/.ollama # model cache
    networks:
      - app-network

  # Pulls the smollm2 model into the ollama by calling the HTTP API
  pull-smollm2:
    image: curlimages/curl:8.16.0
    depends_on:
      ollama:
        condition: service_healthy
    command:
      [
        "curl",
        "-fsS",
        "-X","POST","http://ollama:11434/api/pull",
        "-H","Content-Type: application/json",
        "-d","{\"name\":\"smollm2:135m\"}"
      ]
    restart: "no"
    networks:
      - app-network

  streamlit-app-ollama:
      image: streamlit-app:ollama
      environment:
        - OLLAMA_URL=http://ollama:11434
      depends_on:
        pull-smollm2:
          condition: service_completed_successfully
      restart: unless-stopped
      ports:
        - "8501:8501"
      networks:
        - app-network
volumes:
  ollama:
networks:
  app-network:
    driver: bridge
